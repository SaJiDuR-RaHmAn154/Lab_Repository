{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5e3224",
   "metadata": {},
   "source": [
    "# Week 4: Mining Frequent Itemsets and Association Rules\n",
    "**Objective:** Apply Apriori algorithms  \n",
    "**Topics:** Support, confidence, lift, and frequent patterns  \n",
    "**Tasks:** Run Apriori on market basket dataset and extract rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175f7b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (52, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ToothPaste</th>\n",
       "      <th>PeanutButter</th>\n",
       "      <th>Biscuits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06JAN2008</td>\n",
       "      <td>224</td>\n",
       "      <td>462</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13JAN2008</td>\n",
       "      <td>235</td>\n",
       "      <td>488</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20JAN2008</td>\n",
       "      <td>226</td>\n",
       "      <td>431</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27JAN2008</td>\n",
       "      <td>226</td>\n",
       "      <td>495</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03FEB2008</td>\n",
       "      <td>222</td>\n",
       "      <td>439</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  ToothPaste  PeanutButter  Biscuits\n",
       "0  06JAN2008         224           462       381\n",
       "1  13JAN2008         235           488       398\n",
       "2  20JAN2008         226           431       349\n",
       "3  27JAN2008         226           495       397\n",
       "4  03FEB2008         222           439       367"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "df = pd.read_csv('Lab4_groceries.csv')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbd0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median sales values:\n",
      "ToothPaste      219.0\n",
      "PeanutButter    452.5\n",
      "Biscuits        374.0\n",
      "dtype: float64\n",
      "\n",
      "Generated 52 transactions:\n",
      "T1: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T2: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T3: ['ToothPaste']\n",
      "T4: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T5: ['ToothPaste']\n",
      "T6: []\n",
      "T7: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T8: []\n",
      "T9: ['PeanutButter', 'Biscuits']\n",
      "T10: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T11: ['ToothPaste']\n",
      "T12: []\n",
      "T13: ['PeanutButter', 'Biscuits']\n",
      "T14: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T15: ['ToothPaste']\n",
      "T16: ['PeanutButter', 'Biscuits']\n",
      "T17: []\n",
      "T18: ['PeanutButter', 'Biscuits']\n",
      "T19: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T20: []\n",
      "T21: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T22: ['ToothPaste']\n",
      "T23: ['ToothPaste', 'PeanutButter']\n",
      "T24: []\n",
      "T25: ['PeanutButter', 'Biscuits']\n",
      "T26: ['Biscuits']\n",
      "T27: []\n",
      "T28: ['PeanutButter', 'Biscuits']\n",
      "T29: []\n",
      "T30: ['PeanutButter']\n",
      "T31: []\n",
      "T32: ['PeanutButter', 'Biscuits']\n",
      "T33: []\n",
      "T34: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T35: ['ToothPaste']\n",
      "T36: []\n",
      "T37: []\n",
      "T38: ['PeanutButter', 'Biscuits']\n",
      "T39: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T40: ['ToothPaste']\n",
      "T41: ['PeanutButter', 'Biscuits']\n",
      "T42: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T43: ['ToothPaste']\n",
      "T44: ['ToothPaste', 'PeanutButter']\n",
      "T45: ['Biscuits']\n",
      "T46: ['PeanutButter', 'Biscuits']\n",
      "T47: []\n",
      "T48: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T49: ['ToothPaste']\n",
      "T50: []\n",
      "T51: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T52: ['ToothPaste']\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Calculate median sales for each product\n",
    "median_sales = df[['ToothPaste', 'PeanutButter', 'Biscuits']].median()\n",
    "print(\"Median sales values:\")\n",
    "print(median_sales)\n",
    "\n",
    "transactions = []\n",
    "for _, row in df.iterrows():\n",
    "    transaction = []\n",
    "    if row['ToothPaste'] > median_sales['ToothPaste']:\n",
    "        transaction.append('ToothPaste')\n",
    "    if row['PeanutButter'] > median_sales['PeanutButter']:\n",
    "        transaction.append('PeanutButter')\n",
    "    if row['Biscuits'] > median_sales['Biscuits']:\n",
    "        transaction.append('Biscuits')\n",
    "    transactions.append(transaction)\n",
    "\n",
    "print(f\"\\nGenerated {len(transactions)} transactions:\")\n",
    "for i, transaction in enumerate(transactions[:]):\n",
    "    print(f\"T{i+1}: {transaction}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a189c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database D:\n",
      "T1: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T2: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T3: ['ToothPaste']\n",
      "T4: ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
      "T5: ['ToothPaste']\n",
      "... (52 total transactions)\n",
      "Min support count = 13\n",
      "\n",
      "C1:\n",
      "  {ToothPaste}: 25\n",
      "  {PeanutButter}: 26\n",
      "  {Biscuits}: 25\n",
      "\n",
      "L1:\n",
      "  {ToothPaste}: 25\n",
      "  {PeanutButter}: 26\n",
      "  {Biscuits}: 25\n",
      "\n",
      "C2:\n",
      "  {PeanutButter ToothPaste}: 15\n",
      "  {Biscuits ToothPaste}: 13\n",
      "  {Biscuits PeanutButter}: 23\n",
      "\n",
      "L2:\n",
      "  {PeanutButter ToothPaste}: 15\n",
      "  {Biscuits ToothPaste}: 13\n",
      "  {Biscuits PeanutButter}: 23\n",
      "\n",
      "C3:\n",
      "  {Biscuits PeanutButter ToothPaste}: 13\n",
      "\n",
      "L3:\n",
      "  {Biscuits PeanutButter ToothPaste}: 13\n"
     ]
    }
   ],
   "source": [
    "def calculate_support(itemset, transactions):\n",
    "    count = 0\n",
    "    for transaction in transactions:\n",
    "        if all(item in transaction for item in itemset):\n",
    "            count += 1\n",
    "    return count / len(transactions)\n",
    "\n",
    "def generate_candidates(frequent_itemsets, k):\n",
    "    candidates = []\n",
    "    n = len(frequent_itemsets)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            union = frequent_itemsets[i] | frequent_itemsets[j]\n",
    "            if len(union) == k:\n",
    "                candidates.append(union)\n",
    "    return list(set(frozenset(c) for c in candidates))\n",
    "\n",
    "min_support_count = 13\n",
    "items = ['ToothPaste', 'PeanutButter', 'Biscuits']\n",
    "\n",
    "print(\"Database D:\")\n",
    "for i, transaction in enumerate(transactions[:5]):\n",
    "    print(f\"T{i+1}: {transaction}\")\n",
    "print(f\"... ({len(transactions)} total transactions)\")\n",
    "print(f\"Min support count = {min_support_count}\")\n",
    "\n",
    "# C1\n",
    "print(f\"\\nC1:\")\n",
    "C1 = [{item} for item in items]\n",
    "for itemset in C1:\n",
    "    support_count = sum(1 for t in transactions if all(item in t for item in itemset))\n",
    "    print(f\"  {{{list(itemset)[0]}}}: {support_count}\")\n",
    "\n",
    "# L1\n",
    "print(f\"\\nL1:\")\n",
    "L1 = []\n",
    "for itemset in C1:\n",
    "    support_count = sum(1 for t in transactions if all(item in t for item in itemset))\n",
    "    if support_count >= min_support_count:\n",
    "        L1.append(frozenset(itemset))\n",
    "        print(f\"  {{{list(itemset)[0]}}}: {support_count}\")\n",
    "\n",
    "frequent_itemsets = {1: L1}\n",
    "\n",
    "# C2\n",
    "print(f\"\\nC2:\")\n",
    "C2 = [frozenset(combo) for combo in combinations(items, 2)]\n",
    "for itemset in C2:\n",
    "    support_count = sum(1 for t in transactions if all(item in t for item in itemset))\n",
    "    item_list = sorted(list(itemset))\n",
    "    print(f\"  {{{' '.join(item_list)}}}: {support_count}\")\n",
    "\n",
    "# L2\n",
    "print(f\"\\nL2:\")\n",
    "L2 = []\n",
    "for itemset in C2:\n",
    "    support_count = sum(1 for t in transactions if all(item in t for item in itemset))\n",
    "    if support_count >= min_support_count:\n",
    "        L2.append(itemset)\n",
    "        item_list = sorted(list(itemset))\n",
    "        print(f\"  {{{' '.join(item_list)}}}: {support_count}\")\n",
    "\n",
    "if not L2:\n",
    "    print(\"  (empty)\")\n",
    "\n",
    "frequent_itemsets[2] = L2\n",
    "\n",
    "# C3\n",
    "print(f\"\\nC3:\")\n",
    "if len(L2) >= 2:\n",
    "    C3 = generate_candidates(L2, 3)\n",
    "else:\n",
    "    C3 = [frozenset(items)]\n",
    "\n",
    "for itemset in C3:\n",
    "    support_count = sum(1 for t in transactions if all(item in t for item in itemset))\n",
    "    item_list = sorted(list(itemset))\n",
    "    print(f\"  {{{' '.join(item_list)}}}: {support_count}\")\n",
    "\n",
    "# L3\n",
    "print(f\"\\nL3:\")\n",
    "L3 = []\n",
    "for itemset in C3:\n",
    "    support_count = sum(1 for t in transactions if all(item in t for item in itemset))\n",
    "    if support_count >= min_support_count:\n",
    "        L3.append(itemset)\n",
    "        item_list = sorted(list(itemset))\n",
    "        print(f\"  {{{' '.join(item_list)}}}: {support_count}\")\n",
    "\n",
    "if not L3:\n",
    "    print(\"  (empty)\")\n",
    "\n",
    "frequent_itemsets[3] = L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b852840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "Min confidence = 0.6\n",
      "\n",
      "Generating rules from 2-itemsets:\n",
      "\n",
      "Rule 1: {PeanutButter} → {ToothPaste} (Support: 0.288, Confidence: 0.577)\n",
      "\n",
      "        Rule REJECTED (confidence ->0.577 < 0.6)\n",
      "\n",
      "Rule 2: {ToothPaste} → {PeanutButter} (Support: 0.288, Confidence: 0.600)\n",
      "\n",
      "        Rule ACCEPTED (confidence 0.600 >= 0.6)\n",
      "\n",
      "Rule 3: {ToothPaste} → {Biscuits} (Support: 0.250, Confidence: 0.520)\n",
      "\n",
      "        Rule REJECTED (confidence ->0.520 < 0.6)\n",
      "\n",
      "Rule 4: {Biscuits} → {ToothPaste} (Support: 0.250, Confidence: 0.520)\n",
      "\n",
      "        Rule REJECTED (confidence ->0.520 < 0.6)\n",
      "\n",
      "Rule 5: {PeanutButter} → {Biscuits} (Support: 0.442, Confidence: 0.885)\n",
      "\n",
      "        Rule ACCEPTED (confidence 0.885 >= 0.6)\n",
      "\n",
      "Rule 6: {Biscuits} → {PeanutButter} (Support: 0.442, Confidence: 0.920)\n",
      "\n",
      "        Rule ACCEPTED (confidence 0.920 >= 0.6)\n",
      "\n",
      "\n",
      "Generating rules from 3-itemsets:\n",
      "\n",
      "Rule 7: {PeanutButter} → {Biscuits, ToothPaste} (Support: 0.250, Confidence: 0.500)\n",
      "\n",
      "        Rule REJECTED (confidence ->0.500 < 0.6)\n",
      "\n",
      "Rule 8: {ToothPaste} → {Biscuits, PeanutButter} (Support: 0.250, Confidence: 0.520)\n",
      "\n",
      "        Rule REJECTED (confidence ->0.520 < 0.6)\n",
      "\n",
      "Rule 9: {Biscuits} → {PeanutButter, ToothPaste} (Support: 0.250, Confidence: 0.520)\n",
      "\n",
      "        Rule REJECTED (confidence ->0.520 < 0.6)\n",
      "\n",
      "Rule 10: {PeanutButter, ToothPaste} → {Biscuits} (Support: 0.250, Confidence: 0.867)\n",
      "\n",
      "        Rule ACCEPTED (confidence 0.867 >= 0.6)\n",
      "\n",
      "Rule 11: {Biscuits, PeanutButter} → {ToothPaste} (Support: 0.250, Confidence: 0.565)\n",
      "\n",
      "        Rule REJECTED (confidence ->0.565 < 0.6)\n",
      "\n",
      "Rule 12: {Biscuits, ToothPaste} → {PeanutButter} (Support: 0.250, Confidence: 1.000)\n",
      "\n",
      "        Rule ACCEPTED (confidence 1.000 >= 0.6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_confidence(antecedent, consequent, transactions):\n",
    "    antecedent_support = calculate_support(antecedent, transactions)\n",
    "    if antecedent_support == 0:\n",
    "        return 0\n",
    "    rule_support = calculate_support(antecedent | consequent, transactions)\n",
    "    return rule_support / antecedent_support\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "min_confidence = 0.6\n",
    "print(f\"Min confidence = {min_confidence}\")\n",
    "\n",
    "rule_count = 0\n",
    "\n",
    "for level in range(2, len(frequent_itemsets) + 1):\n",
    "    if not frequent_itemsets[level]:\n",
    "        print(f\"\\nNo frequent {level}-itemsets found for rule generation\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nGenerating rules from {level}-itemsets:\\n\")\n",
    "    for itemset in frequent_itemsets[level]:\n",
    "        if len(itemset) < 2:\n",
    "            continue\n",
    "        \n",
    "        for i in range(1, len(itemset)):\n",
    "            \n",
    "            for antecedent in combinations(itemset, i):\n",
    "                antecedent = frozenset(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                \n",
    "                support = calculate_support(itemset, transactions)\n",
    "                confidence = calculate_confidence(antecedent, consequent, transactions)\n",
    "                \n",
    "                ant_str = ', '.join(sorted(antecedent))\n",
    "                con_str = ', '.join(sorted(consequent))\n",
    "                \n",
    "                rule_count += 1\n",
    "                print(f\"Rule {rule_count}: {{{ant_str}}} → {{{con_str}}} (Support: {support:.3f}, Confidence: {confidence:.3f})\")\n",
    "\n",
    "                if confidence >= min_confidence:\n",
    "                    print(f\"\\n        Rule ACCEPTED (confidence {confidence:.3f} >= {min_confidence})\\n\")\n",
    "                else:\n",
    "                    print(f\"\\n        Rule REJECTED (confidence ->{confidence:.3f} < {min_confidence})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ca3a1",
   "metadata": {},
   "source": [
    "# Conclusion and Key Findings\n",
    "\n",
    "## Summary of Results\n",
    "\n",
    "This lab successfully implemented the Apriori algorithm manually to mine frequent itemsets and generate association rules from the grocery sales dataset. The key findings are:\n",
    "\n",
    "### Frequent Itemsets Discovery\n",
    "- **1-itemsets (L1)**: All three individual products (ToothPaste, PeanutButter, Biscuits) met the minimum support threshold of 13 transactions\n",
    "- **2-itemsets (L2)**: Two pairs were found to be frequent: {Biscuits, PeanutButter} and {Biscuits, ToothPaste}\n",
    "- **3-itemsets (L3)**: The combination of all three products {Biscuits, PeanutButter, ToothPaste} also met the support threshold\n",
    "\n",
    "### Association Rules Analysis\n",
    "The algorithm generated multiple association rules with varying confidence levels:\n",
    "- **Strong rules** (confidence ≥ 0.6): Rules involving Biscuits as either antecedent or consequent showed high confidence\n",
    "- **Weak rules** (confidence < 0.6): Some individual product rules did not meet the minimum confidence threshold\n",
    "\n",
    "### Algorithm Performance\n",
    "- **Manual Implementation**: Successfully avoided built-in libraries and implemented core Apriori functions from scratch\n",
    "- **Step-by-step Process**: Clear visualization of C1→L1→C2→L2→C3→L3 progression\n",
    "- **Transaction Generation**: Effective conversion of continuous sales data to binary transactions using median thresholds\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "1. **Market Basket Patterns**: Biscuits appear to be a central product in customer purchasing behavior, frequently bought together with other items\n",
    "2. **Support vs Confidence**: While itemsets may have sufficient support, the confidence of derived rules can vary significantly\n",
    "3. **Algorithm Scalability**: The manual implementation demonstrates the exponential nature of candidate generation in larger datasets\n",
    "\n",
    "## Technical Achievements\n",
    "\n",
    "- Implemented manual support counting without external libraries\n",
    "- Created custom candidate generation functions\n",
    "- Successfully handled the complete Apriori workflow from data preprocessing to rule evaluation\n",
    "- Generated interpretable output showing both accepted and rejected association rules\n",
    "\n",
    "## Future Work\n",
    "\n",
    "- **Optimization**: Implement pruning strategies to reduce computational complexity\n",
    "- **Extended Analysis**: Apply lift and other interestingness measures beyond confidence\n",
    "- **Larger Datasets**: Test the algorithm on datasets with more products and transactions\n",
    "- **Comparison**: Benchmark against optimized library implementations for performance analysis\n",
    "\n",
    "This lab provides a solid foundation for understanding frequent pattern mining and demonstrates the practical application of the Apriori algorithm in market basket analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
